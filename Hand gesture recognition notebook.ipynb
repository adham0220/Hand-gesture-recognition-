{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0498224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data collection code\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "folder = r\"D:\\depi project\\Data\\Y\"\n",
    "os.makedirs(folder, exist_ok=True) \n",
    "offset = 20\n",
    "imgSize = 300\n",
    "counter = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"❌ Failed to read from camera.\")\n",
    "        break\n",
    "\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "        imgHeight, imgWidth, _ = img.shape\n",
    "        x1 = max(x - offset, 0)\n",
    "        y1 = max(y - offset, 0)\n",
    "        x2 = min(x + w + offset, imgWidth)\n",
    "        y2 = min(y + h + offset, imgHeight)\n",
    "\n",
    "        imgCrop = img[y1:y2, x1:x2]\n",
    "\n",
    "        if imgCrop.size != 0:\n",
    "            imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "\n",
    "            aspectRatio = h / w\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wGap + wCal] = imgResize\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hGap + hCal, :] = imgResize\n",
    "            cv2.imshow(\"ImageCrop\", imgCrop)\n",
    "            cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "    cv2.putText(img, f'Images: {counter}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1.5, (255, 0, 255), 3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"s\"):\n",
    "        if 'imgWhite' in locals():\n",
    "            counter += 1\n",
    "            imgName = f'{folder}/Image_{time.time()}.jpg'\n",
    "            cv2.imwrite(imgName, imgWhite)\n",
    "            print(f\"✅ Saved: {imgName}\")\n",
    "        else:\n",
    "            print(\"⚠️ No hand detected. Try again.\")\n",
    "    elif key == ord(\"q\"):\n",
    "        print(\"🛑 Quitting...\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc596d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "dataset_path = r\"D:\\depi project\\Data\"\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "model.save(r\"D:\\depi project\\training model\\keras_Model.h5\")\n",
    "class_indices = train_generator.class_indices\n",
    "with open(r\"D:\\depi project\\training model\\labels.txt\", \"w\") as f:\n",
    "    for label in class_indices:\n",
    "        f.write(f\"{label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test code\n",
    "import tensorflow.keras as keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "from tensorflow.keras.layers import DepthwiseConv2D as KerasDepthwiseConv2D\n",
    "\n",
    "class CustomDepthwiseConv2D(KerasDepthwiseConv2D):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        groups = kwargs.pop('groups', 1)  \n",
    "        super().__init__(*args, **kwargs)  \n",
    "        self.groups = groups  \n",
    "custom_objects = {\n",
    "    'DepthwiseConv2D': CustomDepthwiseConv2D\n",
    "}\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, labelsPath=None):\n",
    "        self.labelsPath = labelsPath\n",
    "        self.model = None  \n",
    "        if self.labelsPath:\n",
    "            with open(labelsPath, \"r\") as f:\n",
    "                self.labels = [line.strip() for line in f.readlines()]\n",
    "        else:\n",
    "            self.labels = []\n",
    "\n",
    "    def set_model(self, model):\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def getPrediction(self, img, draw=False):\n",
    "       \n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not set. Please set the model using set_model().\")\n",
    "        img_resized = cv2.resize(img, (224, 224)) \n",
    "        img_array = np.array(img_resized) / 255.0 \n",
    "        img_array = np.expand_dims(img_array, axis=0) \n",
    "\n",
    "        # Predict using the model\n",
    "        prediction = self.model.predict(img_array)\n",
    "        index = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "        if draw:\n",
    "            cv2.putText(img, f\"Pred: {self.labels[index]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        return self.labels[index], index\n",
    "\n",
    "model_path = r\"D:\\depi project\\keras_model.h5\"\n",
    "labels_path = r\"D:\\depi project\\labels.txt\"\n",
    "model = keras.models.load_model(model_path, compile=False, custom_objects=custom_objects)\n",
    "classifier = Classifier(labelsPath=labels_path)\n",
    "classifier.set_model(model)  \n",
    "offset = 20\n",
    "imgSize = 300\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "        y1 = max(0, y - offset)\n",
    "        y2 = min(img.shape[0], y + h + offset)\n",
    "        x1 = max(0, x - offset)\n",
    "        x2 = min(img.shape[1], x + w + offset)\n",
    "\n",
    "        imgCrop = img[y1:y2, x1:x2]\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "\n",
    "        try:\n",
    "            aspectRatio = h / w\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wGap + wCal] = imgResize\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hGap + hCal, :] = imgResize\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "            label_text = prediction\n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset - 50), (x - offset + 90, y - offset - 50 + 50), (255, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(imgOutput, label_text, (x, y - 26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset), (x + w + offset, y + h + offset), (255, 0, 255), 4)\n",
    "\n",
    "            cv2.imshow(\"ImageCrop\", imgCrop)\n",
    "            cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Resize error:\", e)\n",
    "\n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
